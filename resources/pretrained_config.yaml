mode: "patch"

master:
  model_name: "bert-base-uncased"
  type: "bert"
  enhance_feat: True

loader:
  tokenizer_sentence:
    max_length: 512
    padding: "max_length"
    truncation: True
    return_tensors: "tf"
  tokenizer_token:
    max_length: 16
    padding: max_length
    truncation: True
    return_tensors: "tf"
  generator:
    feature_names: "count-syllabels|count-morphemes|count-length"
    list_frequency: "google|wikipedia|subtlex-us|subtlex-uk"

regressor:
  layer_type: "bigru"
  sentence_unit: 64
  token_unit: 64
  dropout_rate: 0.2
  dense_unit: 4

trainer:
  lr: 0.000005
  batch_size: 2
  epochs: 10
  early_stopping_patience: 3
  reduce_lr_factor: 0.2
  reduce_lr_patience: 2
  reduce_lr_min: 0.00000001
  
  train_separately: True
  separate_train:
    lr: 0.0001
    batch_size: 4
    epochs: 5
    early_stopping_patience: 3
    reduce_lr_factor: 0.2
    reduce_lr_patience: 2
    reduce_lr_min: 0.00000001